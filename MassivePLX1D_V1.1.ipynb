{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Massive PLAXIS calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"left\" style=\"width: 90%\"><img src=\"info/logofiuba.png\" width=\"150\" align=\"right\"/><img src=\"info/LogoSRK.jpeg\" width=\"195\" align=\"right\" /></div>\n",
    "<br>\n",
    "<font style=\"font-family:sans-serif\" color=\"grey\" vspace=\"0.1em\">\n",
    "Coded by<br>\n",
    "<hr style=\"margin:0.1em; solid lightgrey\" width=\"90%\" align=\"left\" margin=\"0.5em\">\n",
    "<ul>\n",
    "    <li>N. Tasso - <a href = \"mailto: ntasso@srk.com.ar\">ntasso@srk.com.ar</a> - <img src=\"info/Version.gif\" > </li></ul>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Usage</b><br>\n",
    "<hr style=\"margin:0.1em; solid lightgrey\" width=\"90%\" align=\"left\" margin=\"0.5em\">\n",
    "<ul>\n",
    "    <li>Create and calculates 1D models in Plaxis, extract the data and uploads to a Google Drive folder.</li>\n",
    "</ul></div>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Input</b><br>\n",
    "<hr style=\"margin:0.1em; solid lightgrey\" width=\"90%\" align=\"left\" margin=\"0.5em\">\n",
    "<ul>\n",
    "    <li>Statigraphy: geometry and model parameters</li>\n",
    "    <li>API key of Google Drive</li>\n",
    "</ul></div>\n",
    "<div class=\"alert alert-block alert-success\">   \n",
    "<b>Output</b><br>\n",
    "<hr style=\"margin:0.1em; solid lightgrey\" width=\"90%\" align=\"left\" margin=\"0.5em\">\n",
    "<ul>\n",
    "    <li>Uploads automatically</li>\n",
    "</ul>\n",
    "</div>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google drive lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google drive libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth #pip install pydrive in anaconda prompt\n",
    "from pydrive.drive import GoogleDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google drive functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move file inside Google drive\n",
    "def MoveDriveFile(file_id,new_parent):\n",
    "    files = drive.auth.service.files()\n",
    "    file  = files.get(fileId= file_id, fields= 'parents').execute()\n",
    "    prev_parents = ','.join(p['id'] for p in file.get('parents'))\n",
    "    file  = files.update( fileId = file_id,\n",
    "                          addParents = new_parent,\n",
    "                          removeParents = prev_parents,\n",
    "                          fields = 'id, parents',\n",
    "                          ).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google authorization. Json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To upload the data to Google Drive you need to have an API key (see: https://developers.google.com/workspace/guides/create-credentials). This API key is a json file commonly named as \"client_secrets.json\". The json file must be saved at the same location of this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have you json file named as \"client_secrets.json\"?\n",
    "gauth = GoogleAuth()           \n",
    "drive = GoogleDrive(gauth)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google drive folder's links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Google Drive folder's link can be obtained from the URL of the folder. for example if the URL of the folder is: https://drive.google.com/drive/u/1/folders/1XcSLT6M9w2ODUHu7VV3gSZnj4Z1FvAo8, the link is '1XcSLT6M9w2ODUHu7VV3gSZnj4Z1FvAo8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_folder= '' # The main Google Drive folder of the project\n",
    "Acalcular_folder='' # the Google Drive folder which contains the seismic records to be calculated\n",
    "Enproceso_folder='' # the Google Drive folder which contains the seismic records that are being calculated\n",
    "Terminados_folder='' # the Google Drive folder which contains the seismic records calculated\n",
    "Resultados_folder='' # the Google Drive folder which collects the output data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLAXIS lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLAXIS libraries and sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was created with the PLAXIS version 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plxscripting.easy import *\n",
    "\n",
    "localhostport_input = 10000\n",
    "localhostport_output = 10001\n",
    "\n",
    "s_i, g_i = new_server('localhost', localhostport_input, password='')\n",
    "s_o, g_o = new_server('localhost', localhostport_output, password='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLAXIS functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HSSSmall material\n",
    "def Create_HSsmall(Name, Mat):\n",
    "    g_i.soilmat(\n",
    "        # --------------------- General\n",
    "        'MaterialName',Name,\n",
    "        'SoilModel',int(Mat[0]),\n",
    "        'DrainageType',int(Mat[1]), #0 Drained, 1 Undrained.\n",
    "        'gammaUnsat',Mat[2],\n",
    "        'gammaSat',Mat[3],\n",
    "        'RayleighAlpha',Mat[4],\n",
    "        'RayleighBeta',Mat[5],\n",
    "        # --------------------- Parameters\n",
    "        'E50ref',Mat[6],\n",
    "        'Eoedref',Mat[7],\n",
    "        'EurRef', Mat[8],\n",
    "        'powerm',Mat[9],\n",
    "        'cref',Mat[10],\n",
    "        'phi',Mat[11],\n",
    "        'gamma07',Mat[12],\n",
    "        'G0ref',Mat[13],\n",
    "\n",
    "        'nu',Mat[14],\n",
    "        'K0nc',Mat[15],\n",
    "        #'Rf',Param[14],\n",
    "        # -------------------- Groundwater\n",
    "        'HydraulicModel',int(Mat[16]),\n",
    "        'FlowDataModel',Mat[17],\n",
    "        'perm_primary_horizontal_axis',Mat[18],\n",
    "        'perm_vertical_axis',Mat[19],\n",
    "        # -------------------- Initial\n",
    "        'K0Determination',int(Mat[20]),\n",
    "        'K0Primary',Mat[21],\n",
    "        #'OCR',Param[18],\n",
    "        'POP',int(Mat[22]),\n",
    "    )\n",
    "    \n",
    "# Create PM4Sand material\n",
    "def Create_PM4Sand(Name,Dr,Mat):\n",
    "       g_i.soilmat(\n",
    "        # -------------------- General\n",
    "        'MaterialName'  , Name,\n",
    "        'SoilModel'         , 100               , \n",
    "        'UserdefinedIndex'  , 0                 ,\n",
    "        'UserDLLName'       , 'pm4sand64.dll'   ,\n",
    "        'Usermodel'         , 'PM4Sand'         ,\n",
    "        'DrainageType'      , int(Mat[0])          , #0 Drained, 1 Undrained.\n",
    "        'gammaUnsat'        , Mat[1]        ,\n",
    "        'gammaSat'          , Mat[2]          ,\n",
    "        'RayleighAlpha'     , Mat[3]     , #From example in PLAXIS manual. VERIFY\n",
    "        'RayleighBeta'      , Mat[4]      , #From example in PLAXIS manual. VERIFY\n",
    "        # -------------------- Parameters\n",
    "        'User1'     , Dr   , #DR0\n",
    "        'User2'     , 167*np.sqrt(46*(Dr**2)+2.5)                , #G0\n",
    "        'User3'     , Mat[5]               , #hp0. VER. UTILIZAN EL PROCEDIMIENTO DE BOULANGER & IDRISS (2016)\n",
    "        'User4'     , Mat[6]                , #pA (Default PLAXIS manual)\n",
    "        'User5'     , Mat[7]              , #emax (Default PLAXIS manual)\n",
    "        'User6'     , Mat[8]              , #emin (Default PLAXIS manual)\n",
    "        'User7'     , Mat[9]              , #nb (Default PLAXIS manual)\n",
    "        'User8'     , Mat[10]                , #nd (Default PLAXIS manual)\n",
    "        'User9'     , Mat[11]             , #phi_cv (Default PLAXIS manual)\n",
    "        'User10'    , Mat[12]                , #nu (Default PLAXIS manual)\n",
    "        'User11'    , Mat[13]                 , #Q (Default PLAXIS manual)\n",
    "        'User12'    , Mat[14]                 , #R (Default PLAXIS manual)\n",
    "        'User13'    , Mat[15]            , #PostShake (Default PLAXIS manual)\n",
    "        # -------------------- Permeabilidad\n",
    "        'HydraulicModel'   ,                   int(Mat[16]),\n",
    "        'FlowDataModel'   ,                    Mat[17],\n",
    "        'perm_primary_horizontal_axis',       Mat[18], #from galerazo. VERIFY\n",
    "        'perm_vertical_axis',                 Mat[19], #from galerazo. VERIFY\n",
    "        # -------------------- Interface parameters\n",
    "        'Gref'              , Mat[20]              , #from previous projects. VERIFY\n",
    "        'EoedRef'           , Mat[21]            , #from previous projects. VERIFY\n",
    "        'UdPower'           , Mat[22]          , #from previous projects. VERIFY\n",
    "        'Pref'              , Mat[23]              , #from previous projects. VERIFY\n",
    "        'UDPRef'            , Mat[24]            , #from previous projects. VERIFY\n",
    "        'cref'              , Mat[25]              , #from previous projects. VERIFY\n",
    "        'phi'               , Mat[26]               , #from previous projects. VERIFY\n",
    "        'psi'               , Mat[27]             ,  #from previous projects. VERIFY\n",
    "        # ------------------- Estado inicial de tensiones\n",
    "        'K0Determination',int(Mat[28]),\n",
    "        'K0Primary',Mat[29],\n",
    "        )\n",
    "# Create linear elastic material\n",
    "def Create_LE(Name,Param):\n",
    "    g_i.soilmat(\n",
    "        # --------------------- General\n",
    "        'MaterialName',Name,\n",
    "        'SoilModel',1,\n",
    "        'DrainageType',0,\n",
    "        'gammaUnsat',Param[0],\n",
    "        'gammaSat',Param[1],\n",
    "        'RayleighAlpha',Param[2],\n",
    "        'RayleighBeta',Param[3],\n",
    "        # --------------------- Parameters\n",
    "        'nu',Param[4],\n",
    "        'Eref', Param[5],\n",
    "        'perm_primary_horizontal_axis',Param[6],\n",
    "        'perm_vertical_axis',Param[7],\n",
    "        # -------------------- Initial\n",
    "        'K0Determination',0,\n",
    "        'K0Primary',0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was developed to run the cases of the site-response analyses of the paper: N. Tasso, M. Sottile, A. Sfriso (2023). Seismic liquefaction potential assessment by means of automated numerical modelling. (<a href='https://www.researchgate.net/publication/371946995_Seismic_liquefaction_potential_assessment_by_means_of_automated_numerical_modelling?_sg%5B0%5D=OaDDQVy7-JBEYk2UQpv2Gr06DobCihB5bcrj-QRQGlKXkbipKKyM7hxOVSsAZ5AVvf7H9XBV45a6z80aA2uGxxSBbDci9cLUr4yFTxDn.qhBLUwt1EumXRN7L7b3vmjnG03Ol2z3ZG4KLwQl7Rq4cJa5V7h66o16OUYJ3xJVB5dK6dchTcTJsMLKED4oaOw'>ResearchGate link</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"info\\scheme.PNG\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LocalData_folder = 'Local folders/LocalData/'\n",
    "LocalSismos_folder = 'Local folders/SeismicRecords/'\n",
    "LocalResultados_folder = 'Local folders/Results/'\n",
    "LocalTerminados_folder = 'Local folders/Done/'\n",
    "LocalBackup_folder = 'Local folders/Backup/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Persona = 'NT' # Who are you? Just to add to the name of the files you upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download parameters from G. Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the files in the main folder\n",
    "file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(Main_folder)}).GetList()\n",
    "\n",
    "for file in file_list:\n",
    "\n",
    "    # the Props.csv file contains the values of Dr, HC and HL that are going to be iterated\n",
    "    if file['title'].endswith('Props.csv'):   \n",
    "        file.GetContentFile(file['title'])\n",
    "        shutil.move('Props.csv',LocalData_folder+'Props.csv')\n",
    "        Props = pd.read_csv(LocalData_folder+'Props.csv', delimiter=\";\")\n",
    "\n",
    "    # the NonIterativeParameters.csv contains the constant parameters (these could have been added directly in the code)\n",
    "    if file['title'].endswith('NonIterativeParameters.csv'):   \n",
    "        file.GetContentFile(file['title'])\n",
    "        shutil.move('NonIterativeParameters.csv',LocalData_folder+'NonIterativeParameters.csv')\n",
    "        NonItParam = pd.read_csv(LocalData_folder+'NonIterativeParameters.csv', delimiter=\",\")\n",
    "    \n",
    "    # the NonLiqMat.csv contains the material parameters of the non liquefiable soils\n",
    "    if file['title'].endswith('NonLiqMat.csv'):   \n",
    "        file.GetContentFile(file['title'])\n",
    "        shutil.move('NonLiqMat.csv',LocalData_folder+'NonLiqMat.csv')\n",
    "        NonLiqMat = pd.read_csv(LocalData_folder+'NonLiqMat.csv', delimiter=\",\")\n",
    "\n",
    "    # the LiqMat.csv contains the material parameters of the liquefiable soil\n",
    "    if file['title'].startswith('LiqMat.csv'):   \n",
    "        file.GetContentFile(file['title'])\n",
    "        shutil.move('LiqMat.csv',LocalData_folder+'LiqMat.csv')\n",
    "        LiqMat = pd.read_csv(LocalData_folder+'LiqMat.csv', delimiter=\",\")\n",
    "\n",
    "    # the RocaIntacta.csv contains the material parameters linear elastic rock at the base of the model\n",
    "    if file['title'].startswith('RocaIntacta.csv'):   \n",
    "        file.GetContentFile(file['title'])\n",
    "        shutil.move('RocaIntacta.csv',LocalData_folder+'RocaIntacta.csv')\n",
    "        RocaIntacta = pd.read_csv(LocalData_folder+'RocaIntacta.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract some non-iterable parameters from NonIterativeParameters.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Htot = int(NonItParam['Parametros'][0]) # Total height of the soil column\n",
    "Hrec = int(NonItParam['Parametros'][1]) # height measured from the surface were stresspoints are going to be added\n",
    "g = NonItParam['Parametros'][2] # unit multiplier to change to m/s2\n",
    "Sismossimultaneo = int(NonItParam['Parametros'][3]) # number of seismic to be run simultaneously\n",
    "Lx = NonItParam['Parametros'][4] # width of the soil column\n",
    "step = NonItParam['Parametros'][5] #separation of the stresspoints\n",
    "\n",
    "# drainage condition\n",
    "if NonItParam['Parametros'][6] == 0:\n",
    "    TIPO = 'drained'\n",
    "if NonItParam['Parametros'][6] ==1:\n",
    "    TIPO = 'undrained'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start running models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ciclo in range(500):\n",
    "    \n",
    "    # Create a file list of the seismic record to be run that are inside the ToCalculate Google Drive folder\n",
    "    file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(Acalcular_folder)}).GetList()\n",
    "\n",
    "    # select some of the seismic records\n",
    "    for j in range(min(Sismossimultaneo, len(file_list))):\n",
    "        # Download the seismic record\n",
    "        file_list[j].GetContentFile(file_list[j]['title'])\n",
    "\n",
    "        # Move the seismic record to the Calculating Google Drive folder\n",
    "        MoveDriveFile(file_list[j]['id'],Enproceso_folder)\n",
    "\n",
    "        # Move the seismic record to the Calculating local folder\n",
    "        shutil.move(file_list[j]['title'],LocalSismos_folder+file_list[j]['title'])\n",
    "        print(file_list[j]['title'])\n",
    "\n",
    "    # Iterate the height of the liquefiable material\n",
    "    for HC in Props['H1'].dropna():\n",
    "\n",
    "        # Iterate the height of the superficial material\n",
    "        for HL in Props['H2'].dropna():\n",
    "\n",
    "                # Create a new PLAXIS model\n",
    "                s_i.new()\n",
    "\n",
    "                # Apply project settings\n",
    "                g_i.Project.UnitTime = 's'\n",
    "                g_i.Project.ElementType = '15-Noded'\n",
    "\n",
    "                # Create the materials\n",
    "                Create_HSsmall('NonLiquefiable', NonLiqMat['Parametros'])\n",
    "                Create_HSsmall('BelowLiquefiable', NonLiqMat['Parametros'])\n",
    "                Create_LE('Bedrock',RocaIntacta['Parametros'])\n",
    "\n",
    "                # Create the polygons\n",
    "                for i in range(Htot):\n",
    "                    g_i.polygon((0,-i),(Lx,-i),(Lx,-i-1),(0,-i-1))\n",
    "                    if HC>i:\n",
    "                        g_i.Soils[-1].Material = g_i.Materials[0]\n",
    "                    else:\n",
    "                        g_i.Soils[-1].Material = g_i.Materials[1]\n",
    "\n",
    "                # A final polygon that will be the Bedrock\n",
    "                g_i.polygon((0,-Htot),(Lx,-Htot),(Lx,-(Htot+Lx)),(0,-(Htot+Lx)))\n",
    "\n",
    "                # Assign the materials to the polygons\n",
    "                g_i.Soils[-1].Material = g_i.Materials[2]\n",
    "\n",
    "\n",
    "                # Create interface, line displacement and load\n",
    "                g_i.gotostructures()\n",
    "                g_i.neginterface((Lx,-(Htot+Lx)),(0,-(Htot+Lx)))\n",
    "                g_i.linedispl((Lx,-(Htot+Lx)),(0,-(Htot+Lx)))\n",
    "\n",
    "\n",
    "                # Mesh the model\n",
    "                g_i.gotomesh()\n",
    "                for i in range(len(g_i.BoundaryLine)):\n",
    "                    g_i.BoundaryLine[i].CoarsenessFactor = 0.5\n",
    "                for i in range(len(g_i.Polygons)):\n",
    "                    g_i.Polygons[i].CoarsenessFactor = 0.5\n",
    "                g_i.mesh(0.1)\n",
    "\n",
    "                # Add a node at the surface\n",
    "                g_i.viewmesh()\n",
    "                g_o.addcurvepoint(\"node\", (Lx/2,0))\n",
    "\n",
    "                # Add stresspoints\n",
    "                for i in range(int(Hrec/step)):\n",
    "                    g_o.addcurvepoint(\"stresspoint\", (Lx/2,-i*step-0.25))\n",
    "                g_o.update()\n",
    "\n",
    "                # Add Watertable\n",
    "                g_i.gotoflow()\n",
    "                g_i.waterlevel((0,-HC),(Lx,-HC))\n",
    "\n",
    "                # Go to stages tab\n",
    "                g_i.gotostages()\n",
    "\n",
    "                # Activate polygons at the initial phase\n",
    "                for i in range(len(g_i.Polygons)):\n",
    "                    g_i.activate(g_i.Polygons[i], g_i.Phases[0])\n",
    "\n",
    "                # Create a nil plastic phase\n",
    "                g_i.phase(g_i.Phases[0])\n",
    "                g_i.Phases[1].Deform.IgnoreUndrainedBehaviour = True\n",
    "\n",
    "                i = 0\n",
    "                # For every selected seismic record\n",
    "                for root, dirs, files in os.walk(LocalSismos_folder):\n",
    "                    for file in files:\n",
    "                        i += 1\n",
    "                        if file.endswith(\".csv\"):\n",
    "\n",
    "                            # Load the seismic record to Plaxis\n",
    "                            DATA = np.loadtxt(LocalSismos_folder+file, delimiter=\"\\t\", skiprows=1)\n",
    "                            ACEL = DATA[:,1]*g\n",
    "                            TIME = DATA[:,0]\n",
    "                            ACEL[0] = 0\n",
    "                            dt = TIME[5]-TIME[4]\n",
    "                            filename = file[:-4].split('_')[0]+'_'+str(i)\n",
    "                            g_i.displmultiplier().Name = filename\n",
    "                            exec('g_i.'+filename+'.Signal=1')\n",
    "                            exec('g_i.'+filename+'.DataType=2')\n",
    "                            A = sorted([i,j] for i,j in zip(TIME,ACEL))\n",
    "                            values = '],A['.join(str(int(i)) for i in np.linspace(0,len(A)-1,len(A)))\n",
    "                            values0 = 'A['+values+']'\n",
    "                            exec('g_i.'+filename+'.Table.set('+values0+')')\n",
    "                            exec('g_i.'+filename+'.DriftCorrection = True')\n",
    "                            plt.plot(TIME,ACEL)\n",
    "                            plt.show()\n",
    "\n",
    "                            # Create a dynamic phase\n",
    "                            ## Phase settings\n",
    "                            g_i.phase(g_i.Phases[1])\n",
    "                            g_i.Phases[-1].Identification = filename\n",
    "                            g_i.Phases[-1].DeformCalcType = 'dynamic'\n",
    "                            g_i.Phases[-1].Deform.TimeIntervalSeconds = int(TIME[-1])\n",
    "                            g_i.Phases[-1].Deform.ResetTime = True\n",
    "                            g_i.Phases[-1].Deform.UseDefaultIterationParams = False\n",
    "                            m = int((len(ACEL)-1)/0.01*dt)\n",
    "                            n = max(int((len(ACEL)-1)/m),1)\n",
    "                            g_i.Phases[-1].Deform.MaxSteps = int(m)\n",
    "                            g_i.Phases[-1].Deform.TimeStepDetermType = 'Manual'\n",
    "                            g_i.Phases[-1].Deform.SubSteps = int(n)\n",
    "                            g_i.Phases[-1].MaxStepsStored = 1\n",
    "                            g_i.Phases[-1].MaxCores = 1\n",
    "\n",
    "                            ## Boundary conditions\n",
    "                            g_i.Dynamics.BoundaryXMin.set(g_i.Phases[-1],\"Tied degrees of freedom\")\n",
    "                            g_i.Dynamics.BoundaryXMax.set(g_i.Phases[-1],\"Tied degrees of freedom\")\n",
    "                            g_i.Dynamics.BoundaryYMin.set(g_i.Phases[-1],\"Compliant Base\")\n",
    "                            g_i.GroundwaterFLow.BoundaryXMin.set(g_i.Phases[-1],\"Closed\")\n",
    "                            g_i.GroundwaterFLow.BoundaryXMax.set(g_i.Phases[-1],\"Closed\")\n",
    "                            g_i.Deformations.BoundaryXMin.set(g_i.Phases[-1],\"Free\")\n",
    "                            g_i.Deformations.BoundaryXMax.set(g_i.Phases[-1],\"Free\")\n",
    "                            g_i.Deformations.BoundaryYMin.set(g_i.Phases[-1],\"Free\")\n",
    "\n",
    "                            ## Line displacement\n",
    "                            g_i.LineDisplacements[0].Displacement_y.set(g_i.Phases[-1],\"Fixed\")\n",
    "                            g_i.LineDisplacements[0].Displacement_x.set(g_i.Phases[-1],\"Prescribed\")\n",
    "                            g_i.LineDisplacements[0].ux_start.set(g_i.Phases[-1],0.5)\n",
    "                            exec('g_i.DynLineDisplacement_1_1.Multiplierx.set(g_i.Phases[-1],g_i.'+filename+')')\n",
    "                            g_i.activate(g_i.DynLineDisplacement_1_1,g_i.Phases[-1])\n",
    "                            g_i.activate(g_i.LineDisplacements[0],g_i.Phases[-1])\n",
    "\n",
    "                # So far, the model is almost finished. The only thing left is to create the PM4Sand\n",
    "                # material and assign to the liquefiable layer\n",
    "\n",
    "                # For every selected relative density\n",
    "                for Dr in Props['Dr'].dropna():\n",
    "\n",
    "                    # Take time, just to measure how long it takes\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    # Creates the PM4Sand material based on the relative density\n",
    "                    Create_PM4Sand('Liquefiable',Dr/100, LiqMat['Parametros'])\n",
    "\n",
    "                    # Apply to the liquefiable layer in all phases\n",
    "                    for i in range(int(HC),int(HC+HL),1):\n",
    "                        for j in range(len(g_i.Phases)):\n",
    "                            g_i.Soils[i].Material.set(g_i.Phases[j],g_i.Materials[-1])\n",
    "\n",
    "                    # Mark for calculation all phases\n",
    "                    for i in range(len(g_i.Phases)):\n",
    "                        g_i.Phases[i].ShouldCalculate = True\n",
    "\n",
    "                    # Calculate and view PLAXIS output\n",
    "                    g_i.calculate()\n",
    "                    g_i.view(g_i.Phases[2])\n",
    "\n",
    "                    # For every dynamic phase\n",
    "                    for Phase in g_i.Phases[2:]:\n",
    "\n",
    "                        # Creates a dataframe with the results\n",
    "                        Res = pd.DataFrame()\n",
    "\n",
    "                        # For every selected points\n",
    "                        for i in range(len(g_o.CurvePoints[:])):\n",
    "\n",
    "                            # The first point is a node.\n",
    "                            if i == 0:\n",
    "                                # Extract the displacements and the acceleeration of the node\n",
    "                                Res['Ux'] = np.fromstring(g_o.getcurveresultspath(g_o.CurvePoints[i],Phase,Phase,g_o.ResultTypes.Soil.Ux).echo()[1:-1], dtype=float, sep=',')\n",
    "                                Res['Ax'] = np.fromstring(g_o.getcurveresultspath(g_o.CurvePoints[i],Phase,Phase,g_o.ResultTypes.Soil.Ax).echo()[1:-1], dtype=float, sep=',')\n",
    "                                Res['Uy'] = np.fromstring(g_o.getcurveresultspath(g_o.CurvePoints[i],Phase,Phase,g_o.ResultTypes.Soil.Uy).echo()[1:-1], dtype=float, sep=',')\n",
    "                                Res['t'] =  np.linspace(0,(len(Res['Ux'])-1)*0.01,len(Res['Ux']), endpoint=True)\n",
    "                            # the remaining points are stresspoints\n",
    "                            else:\n",
    "                                # Extract strains, shear stress and effective vertical stress\n",
    "                                Res['gamxy - Prof.'+str(i*step-0.5)] = np.fromstring(g_o.getcurveresultspath(g_o.CurvePoints[i],Phase,Phase,g_o.ResultTypes.Soil.Gamxy).echo()[1:-1], dtype=float, sep=',')\n",
    "                                Res['tauxy - Prof.'+str(i*step-0.5)] = np.fromstring(g_o.getcurveresultspath(g_o.CurvePoints[i],Phase,Phase,g_o.ResultTypes.Soil.Sigxy).echo()[1:-1], dtype=float, sep=',')\n",
    "                                Res['sigyyE - Prof.'+str(i*step-0.5)] = np.fromstring(g_o.getcurveresultspath(g_o.CurvePoints[i],Phase,Phase,g_o.ResultTypes.Soil.SigyyE).echo()[1:-1], dtype=float, sep=',')\n",
    "                        \n",
    "                        # Save the Res dataframe\n",
    "                        fase = Phase.Identification.echo().split('\"')[1]\n",
    "                        Res.to_csv(LocalResultados_folder+fase+'HTOT'+str(Htot)+'-HL'+str(HL)+'-HC'+str(HC)+'-Dr'+str(Dr)+Persona+'-'+TIPO+'Version'+str(NonItParam['Parametros'].values[-1])+'.csv', sep=',')\n",
    "                    \n",
    "                    # Close the PLAXIS output\n",
    "                    g_o.close()\n",
    "\n",
    "                    # Print the time\n",
    "                    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    # Upload the data to Google Drive and move the local data to the Bakcup folder\n",
    "    for root, dirs, files in os.walk(LocalResultados_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                shutil.move(LocalResultados_folder+file,LocalBackup_folder+file)  \n",
    "                gfile = drive.CreateFile({'parents': [{'id': Resultados_folder}]})\n",
    "                gfile.SetContentFile(LocalBackup_folder+file)\n",
    "                gfile['title'] = file\n",
    "                gfile.Upload()   \n",
    "\n",
    "    # Move the selected seismic records to the Done local folder\n",
    "    for root, dirs, files in os.walk(LocalSismos_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                shutil.move(LocalSismos_folder+file,LocalTerminados_folder+file)\n",
    "\n",
    "    # Move the selected seismic records to the Done folder in Google Drive\n",
    "    for j in range(min(Sismossimultaneo, len(file_list))):\n",
    "        MoveDriveFile(file_list[j]['id'],Terminados_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6e9acd092280a16e067a9742cdf612d4ca1b57cd7c08fe3222a18320beaa3906"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
